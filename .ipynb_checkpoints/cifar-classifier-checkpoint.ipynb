{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14efcc26",
   "metadata": {},
   "source": [
    "## Pytorch Cifar-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54d273",
   "metadata": {},
   "source": [
    "This is a mini-project implementing Cifar-10 classifier using PyTorch and the concept of Wide Residual Network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00df66",
   "metadata": {},
   "source": [
    "### Importing necessary libraries and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac710ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from model_wrn import wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae7174",
   "metadata": {},
   "source": [
    "### Preprocessing the data using augmentation and normalization (For testing data there is only normalization implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4af1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94455559",
   "metadata": {},
   "source": [
    "### Detect if there is available GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6535b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a508c3",
   "metadata": {},
   "source": [
    "### Load training images of CIFAR-10 twice: one for training, one for validation, with different preprocessing function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710b20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "6.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "11.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "20.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "25.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "30.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "35.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "42.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "49.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "57.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "65.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "73.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "80.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "88.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "98.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c33cf5",
   "metadata": {},
   "source": [
    "### Learning Rate Schedule (Step Dacay):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a469be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if(epoch<61):\n",
    "        lr=0.1\n",
    "    elif(epoch<121):\n",
    "        lr=0.02\n",
    "    elif(epoch<161):\n",
    "        lr=0.004\n",
    "    elif(epoch<=200):\n",
    "        lr=0.0008\n",
    "    #print(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a560d9",
   "metadata": {},
   "source": [
    "### Defining training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f94cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,dataLoader,model):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    print('Epoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataLoader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c5c17",
   "metadata": {},
   "source": [
    "### Defining testing function, the best model will be stored in ./checkpoint-no-cross/ and continuously updated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f2f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,dataLoader,model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_num=0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataLoader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            batch_num+=1\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_num), 100.*correct/total, correct, total))\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint-no-cross'):\n",
    "            os.mkdir('checkpoint-no-cross')\n",
    "        torch.save(state, './checkpoint-no-cross/' + 'ckpt{}.pth'.format(0))\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb734f7",
   "metadata": {},
   "source": [
    "### Using torchsummary to examine the number of parameters in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d775944c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 80, 32, 32]          11,520\n",
      "       BatchNorm2d-5           [-1, 80, 32, 32]             160\n",
      "              ReLU-6           [-1, 80, 32, 32]               0\n",
      "            Conv2d-7           [-1, 80, 32, 32]          57,600\n",
      "            Conv2d-8           [-1, 80, 32, 32]           1,280\n",
      "        BasicBlock-9           [-1, 80, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 80, 32, 32]             160\n",
      "             ReLU-11           [-1, 80, 32, 32]               0\n",
      "           Conv2d-12           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-13           [-1, 80, 32, 32]             160\n",
      "             ReLU-14           [-1, 80, 32, 32]               0\n",
      "           Conv2d-15           [-1, 80, 32, 32]          57,600\n",
      "       BasicBlock-16           [-1, 80, 32, 32]               0\n",
      "     NetworkBlock-17           [-1, 80, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 80, 32, 32]             160\n",
      "             ReLU-19           [-1, 80, 32, 32]               0\n",
      "           Conv2d-20          [-1, 160, 16, 16]         115,200\n",
      "      BatchNorm2d-21          [-1, 160, 16, 16]             320\n",
      "             ReLU-22          [-1, 160, 16, 16]               0\n",
      "           Conv2d-23          [-1, 160, 16, 16]         230,400\n",
      "           Conv2d-24          [-1, 160, 16, 16]          12,800\n",
      "       BasicBlock-25          [-1, 160, 16, 16]               0\n",
      "      BatchNorm2d-26          [-1, 160, 16, 16]             320\n",
      "             ReLU-27          [-1, 160, 16, 16]               0\n",
      "           Conv2d-28          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-29          [-1, 160, 16, 16]             320\n",
      "             ReLU-30          [-1, 160, 16, 16]               0\n",
      "           Conv2d-31          [-1, 160, 16, 16]         230,400\n",
      "       BasicBlock-32          [-1, 160, 16, 16]               0\n",
      "     NetworkBlock-33          [-1, 160, 16, 16]               0\n",
      "      BatchNorm2d-34          [-1, 160, 16, 16]             320\n",
      "             ReLU-35          [-1, 160, 16, 16]               0\n",
      "           Conv2d-36            [-1, 320, 8, 8]         460,800\n",
      "      BatchNorm2d-37            [-1, 320, 8, 8]             640\n",
      "             ReLU-38            [-1, 320, 8, 8]               0\n",
      "           Conv2d-39            [-1, 320, 8, 8]         921,600\n",
      "           Conv2d-40            [-1, 320, 8, 8]          51,200\n",
      "       BasicBlock-41            [-1, 320, 8, 8]               0\n",
      "      BatchNorm2d-42            [-1, 320, 8, 8]             640\n",
      "             ReLU-43            [-1, 320, 8, 8]               0\n",
      "           Conv2d-44            [-1, 320, 8, 8]         921,600\n",
      "      BatchNorm2d-45            [-1, 320, 8, 8]             640\n",
      "             ReLU-46            [-1, 320, 8, 8]               0\n",
      "           Conv2d-47            [-1, 320, 8, 8]         921,600\n",
      "       BasicBlock-48            [-1, 320, 8, 8]               0\n",
      "     NetworkBlock-49            [-1, 320, 8, 8]               0\n",
      "      BatchNorm2d-50            [-1, 320, 8, 8]             640\n",
      "             ReLU-51            [-1, 320, 8, 8]               0\n",
      "           Linear-52                   [-1, 10]           3,210\n",
      "================================================================\n",
      "Total params: 4,289,754\n",
      "Trainable params: 4,289,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 17.88\n",
      "Params size (MB): 16.36\n",
      "Estimated Total Size (MB): 34.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "net = wrn(\n",
    "          num_classes=10,\n",
    "          depth=16,\n",
    "          widen_factor=5,\n",
    "          dropRate=0.3,\n",
    "        )\n",
    "net.cuda()\n",
    "torchsummary.summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838152a",
   "metadata": {},
   "source": [
    "### Training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308110f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> Building model 0..\n",
      "Epoch: 0\n",
      "Loss: 1.595 | Acc: 50.460% (5046/10000)\n",
      "Saving..\n",
      "Epoch: 1\n",
      "Loss: 0.906 | Acc: 67.790% (6779/10000)\n",
      "Saving..\n",
      "Epoch: 2\n",
      "Loss: 0.898 | Acc: 70.420% (7042/10000)\n",
      "Saving..\n",
      "Epoch: 3\n",
      "Loss: 0.806 | Acc: 72.940% (7294/10000)\n",
      "Saving..\n",
      "Epoch: 4\n",
      "Loss: 0.719 | Acc: 75.790% (7579/10000)\n",
      "Saving..\n",
      "Epoch: 5\n",
      "Loss: 0.682 | Acc: 76.860% (7686/10000)\n",
      "Saving..\n",
      "Epoch: 6\n",
      "Loss: 0.866 | Acc: 72.170% (7217/10000)\n",
      "Epoch: 7\n",
      "Loss: 0.583 | Acc: 80.320% (8032/10000)\n",
      "Saving..\n",
      "Epoch: 8\n",
      "Loss: 0.602 | Acc: 79.250% (7925/10000)\n",
      "Epoch: 9\n",
      "Loss: 0.625 | Acc: 79.050% (7905/10000)\n",
      "Epoch: 10\n",
      "Loss: 0.552 | Acc: 81.800% (8180/10000)\n",
      "Saving..\n",
      "Epoch: 11\n",
      "Loss: 0.653 | Acc: 79.030% (7903/10000)\n",
      "Epoch: 12\n",
      "Loss: 0.708 | Acc: 77.730% (7773/10000)\n",
      "Epoch: 13\n",
      "Loss: 0.714 | Acc: 77.220% (7722/10000)\n",
      "Epoch: 14\n",
      "Loss: 0.666 | Acc: 79.840% (7984/10000)\n",
      "Epoch: 15\n",
      "Loss: 0.656 | Acc: 79.800% (7980/10000)\n",
      "Epoch: 16\n",
      "Loss: 0.563 | Acc: 81.590% (8159/10000)\n",
      "Epoch: 17\n",
      "Loss: 0.455 | Acc: 84.680% (8468/10000)\n",
      "Saving..\n",
      "Epoch: 18\n",
      "Loss: 0.664 | Acc: 79.450% (7945/10000)\n",
      "Epoch: 19\n",
      "Loss: 0.607 | Acc: 80.480% (8048/10000)\n",
      "Epoch: 20\n",
      "Loss: 0.610 | Acc: 79.990% (7999/10000)\n",
      "Epoch: 21\n",
      "Loss: 0.568 | Acc: 81.920% (8192/10000)\n",
      "Epoch: 22\n",
      "Loss: 0.495 | Acc: 83.560% (8356/10000)\n",
      "Epoch: 23\n",
      "Loss: 0.782 | Acc: 76.240% (7624/10000)\n",
      "Epoch: 24\n",
      "Loss: 0.755 | Acc: 77.540% (7754/10000)\n",
      "Epoch: 25\n",
      "Loss: 0.531 | Acc: 82.450% (8245/10000)\n",
      "Epoch: 26\n",
      "Loss: 0.446 | Acc: 84.690% (8469/10000)\n",
      "Saving..\n",
      "Epoch: 27\n",
      "Loss: 0.473 | Acc: 84.560% (8456/10000)\n",
      "Epoch: 28\n",
      "Loss: 0.465 | Acc: 84.330% (8433/10000)\n",
      "Epoch: 29\n",
      "Loss: 0.532 | Acc: 82.700% (8270/10000)\n",
      "Epoch: 30\n",
      "Loss: 0.497 | Acc: 83.700% (8370/10000)\n",
      "Epoch: 31\n",
      "Loss: 0.561 | Acc: 82.010% (8201/10000)\n",
      "Epoch: 32\n",
      "Loss: 0.591 | Acc: 81.910% (8191/10000)\n",
      "Epoch: 33\n",
      "Loss: 0.609 | Acc: 81.120% (8112/10000)\n",
      "Epoch: 34\n",
      "Loss: 0.467 | Acc: 84.650% (8465/10000)\n",
      "Epoch: 35\n",
      "Loss: 0.537 | Acc: 82.090% (8209/10000)\n",
      "Epoch: 36\n",
      "Loss: 0.502 | Acc: 83.150% (8315/10000)\n",
      "Epoch: 37\n",
      "Loss: 0.550 | Acc: 82.360% (8236/10000)\n",
      "Epoch: 38\n",
      "Loss: 0.534 | Acc: 82.710% (8271/10000)\n",
      "Epoch: 39\n",
      "Loss: 0.902 | Acc: 72.080% (7208/10000)\n",
      "Epoch: 40\n",
      "Loss: 0.471 | Acc: 84.330% (8433/10000)\n",
      "Epoch: 41\n",
      "Loss: 0.440 | Acc: 85.450% (8545/10000)\n",
      "Saving..\n",
      "Epoch: 42\n",
      "Loss: 0.452 | Acc: 85.060% (8506/10000)\n",
      "Epoch: 43\n",
      "Loss: 0.552 | Acc: 82.270% (8227/10000)\n",
      "Epoch: 44\n",
      "Loss: 0.461 | Acc: 84.660% (8466/10000)\n",
      "Epoch: 45\n",
      "Loss: 0.550 | Acc: 82.440% (8244/10000)\n",
      "Epoch: 46\n",
      "Loss: 0.575 | Acc: 81.360% (8136/10000)\n",
      "Epoch: 47\n",
      "Loss: 0.589 | Acc: 81.230% (8123/10000)\n",
      "Epoch: 48\n",
      "Loss: 0.652 | Acc: 79.480% (7948/10000)\n",
      "Epoch: 49\n",
      "Loss: 0.452 | Acc: 85.090% (8509/10000)\n",
      "Epoch: 50\n",
      "Loss: 0.473 | Acc: 84.250% (8425/10000)\n",
      "Epoch: 51\n",
      "Loss: 0.556 | Acc: 81.750% (8175/10000)\n",
      "Epoch: 52\n",
      "Loss: 0.482 | Acc: 84.750% (8475/10000)\n",
      "Epoch: 53\n",
      "Loss: 0.544 | Acc: 82.940% (8294/10000)\n",
      "Epoch: 54\n",
      "Loss: 0.537 | Acc: 82.760% (8276/10000)\n",
      "Epoch: 55\n",
      "Loss: 0.676 | Acc: 80.060% (8006/10000)\n",
      "Epoch: 56\n",
      "Loss: 0.486 | Acc: 84.010% (8401/10000)\n",
      "Epoch: 57\n",
      "Loss: 0.571 | Acc: 81.440% (8144/10000)\n",
      "Epoch: 58\n",
      "Loss: 0.528 | Acc: 82.900% (8290/10000)\n",
      "Epoch: 59\n",
      "Loss: 0.444 | Acc: 85.220% (8522/10000)\n",
      "Epoch: 60\n",
      "Loss: 0.621 | Acc: 81.050% (8105/10000)\n",
      "Epoch: 61\n",
      "Loss: 0.222 | Acc: 92.300% (9230/10000)\n",
      "Saving..\n",
      "Epoch: 62\n",
      "Loss: 0.219 | Acc: 92.760% (9276/10000)\n",
      "Saving..\n",
      "Epoch: 63\n",
      "Loss: 0.223 | Acc: 92.380% (9238/10000)\n",
      "Epoch: 64\n",
      "Loss: 0.231 | Acc: 92.490% (9249/10000)\n",
      "Epoch: 65\n",
      "Loss: 0.212 | Acc: 93.060% (9306/10000)\n",
      "Saving..\n",
      "Epoch: 66\n",
      "Loss: 0.229 | Acc: 92.610% (9261/10000)\n",
      "Epoch: 67\n",
      "Loss: 0.233 | Acc: 92.590% (9259/10000)\n",
      "Epoch: 68\n",
      "Loss: 0.237 | Acc: 92.450% (9245/10000)\n",
      "Epoch: 69\n",
      "Loss: 0.262 | Acc: 91.890% (9189/10000)\n",
      "Epoch: 70\n",
      "Loss: 0.241 | Acc: 92.320% (9232/10000)\n",
      "Epoch: 71\n",
      "Loss: 0.234 | Acc: 92.660% (9266/10000)\n",
      "Epoch: 72\n",
      "Loss: 0.278 | Acc: 91.570% (9157/10000)\n",
      "Epoch: 73\n",
      "Loss: 0.279 | Acc: 91.590% (9159/10000)\n",
      "Epoch: 74\n",
      "Loss: 0.291 | Acc: 91.150% (9115/10000)\n",
      "Epoch: 75\n",
      "Loss: 0.264 | Acc: 91.890% (9189/10000)\n",
      "Epoch: 76\n",
      "Loss: 0.262 | Acc: 92.000% (9200/10000)\n",
      "Epoch: 77\n",
      "Loss: 0.295 | Acc: 91.210% (9121/10000)\n",
      "Epoch: 78\n",
      "Loss: 0.275 | Acc: 91.770% (9177/10000)\n",
      "Epoch: 79\n",
      "Loss: 0.273 | Acc: 91.700% (9170/10000)\n",
      "Epoch: 80\n",
      "Loss: 0.297 | Acc: 90.720% (9072/10000)\n",
      "Epoch: 81\n",
      "Loss: 0.265 | Acc: 91.800% (9180/10000)\n",
      "Epoch: 82\n",
      "Loss: 0.291 | Acc: 91.310% (9131/10000)\n",
      "Epoch: 83\n",
      "Loss: 0.307 | Acc: 90.980% (9098/10000)\n",
      "Epoch: 84\n",
      "Loss: 0.276 | Acc: 91.620% (9162/10000)\n",
      "Epoch: 85\n",
      "Loss: 0.280 | Acc: 91.380% (9138/10000)\n",
      "Epoch: 86\n",
      "Loss: 0.323 | Acc: 90.850% (9085/10000)\n",
      "Epoch: 87\n",
      "Loss: 0.305 | Acc: 90.660% (9066/10000)\n",
      "Epoch: 88\n",
      "Loss: 0.284 | Acc: 91.560% (9156/10000)\n",
      "Epoch: 89\n",
      "Loss: 0.278 | Acc: 91.430% (9143/10000)\n",
      "Epoch: 90\n",
      "Loss: 0.290 | Acc: 91.040% (9104/10000)\n",
      "Epoch: 91\n",
      "Loss: 0.282 | Acc: 91.580% (9158/10000)\n",
      "Epoch: 92\n",
      "Loss: 0.300 | Acc: 91.580% (9158/10000)\n",
      "Epoch: 93\n",
      "Loss: 0.259 | Acc: 91.950% (9195/10000)\n",
      "Epoch: 94\n",
      "Loss: 0.290 | Acc: 91.100% (9110/10000)\n",
      "Epoch: 95\n",
      "Loss: 0.264 | Acc: 91.720% (9172/10000)\n",
      "Epoch: 96\n",
      "Loss: 0.296 | Acc: 91.420% (9142/10000)\n",
      "Epoch: 97\n",
      "Loss: 0.320 | Acc: 90.230% (9023/10000)\n",
      "Epoch: 98\n",
      "Loss: 0.292 | Acc: 91.130% (9113/10000)\n",
      "Epoch: 99\n",
      "Loss: 0.273 | Acc: 91.570% (9157/10000)\n",
      "Epoch: 100\n",
      "Loss: 0.279 | Acc: 91.570% (9157/10000)\n",
      "Epoch: 101\n",
      "Loss: 0.278 | Acc: 91.810% (9181/10000)\n",
      "Epoch: 102\n",
      "Loss: 0.338 | Acc: 90.400% (9040/10000)\n",
      "Epoch: 103\n",
      "Loss: 0.269 | Acc: 91.950% (9195/10000)\n",
      "Epoch: 104\n",
      "Loss: 0.335 | Acc: 90.010% (9001/10000)\n",
      "Epoch: 105\n",
      "Loss: 0.258 | Acc: 92.050% (9205/10000)\n",
      "Epoch: 106\n",
      "Loss: 0.281 | Acc: 91.580% (9158/10000)\n",
      "Epoch: 107\n",
      "Loss: 0.309 | Acc: 91.150% (9115/10000)\n",
      "Epoch: 108\n",
      "Loss: 0.288 | Acc: 91.380% (9138/10000)\n",
      "Epoch: 109\n",
      "Loss: 0.297 | Acc: 91.290% (9129/10000)\n",
      "Epoch: 110\n",
      "Loss: 0.274 | Acc: 91.720% (9172/10000)\n",
      "Epoch: 111\n",
      "Loss: 0.301 | Acc: 91.020% (9102/10000)\n",
      "Epoch: 112\n",
      "Loss: 0.284 | Acc: 91.640% (9164/10000)\n",
      "Epoch: 113\n",
      "Loss: 0.252 | Acc: 92.220% (9222/10000)\n",
      "Epoch: 114\n",
      "Loss: 0.295 | Acc: 91.330% (9133/10000)\n",
      "Epoch: 115\n",
      "Loss: 0.301 | Acc: 91.030% (9103/10000)\n",
      "Epoch: 116\n",
      "Loss: 0.306 | Acc: 91.300% (9130/10000)\n",
      "Epoch: 117\n",
      "Loss: 0.290 | Acc: 91.670% (9167/10000)\n",
      "Epoch: 118\n",
      "Loss: 0.325 | Acc: 90.830% (9083/10000)\n",
      "Epoch: 119\n",
      "Loss: 0.255 | Acc: 92.320% (9232/10000)\n",
      "Epoch: 120\n",
      "Loss: 0.312 | Acc: 90.800% (9080/10000)\n",
      "Epoch: 121\n",
      "Loss: 0.202 | Acc: 93.960% (9396/10000)\n",
      "Saving..\n",
      "Epoch: 122\n",
      "Loss: 0.201 | Acc: 94.110% (9411/10000)\n",
      "Saving..\n",
      "Epoch: 123\n",
      "Loss: 0.203 | Acc: 94.090% (9409/10000)\n",
      "Epoch: 124\n",
      "Loss: 0.200 | Acc: 94.140% (9414/10000)\n",
      "Saving..\n",
      "Epoch: 125\n",
      "Loss: 0.200 | Acc: 94.130% (9413/10000)\n",
      "Epoch: 126\n",
      "Loss: 0.199 | Acc: 94.350% (9435/10000)\n",
      "Saving..\n",
      "Epoch: 127\n",
      "Loss: 0.208 | Acc: 94.100% (9410/10000)\n",
      "Epoch: 128\n",
      "Loss: 0.207 | Acc: 94.110% (9411/10000)\n",
      "Epoch: 129\n",
      "Loss: 0.206 | Acc: 94.180% (9418/10000)\n",
      "Epoch: 130\n",
      "Loss: 0.208 | Acc: 94.090% (9409/10000)\n",
      "Epoch: 131\n",
      "Loss: 0.203 | Acc: 94.250% (9425/10000)\n",
      "Epoch: 132\n",
      "Loss: 0.207 | Acc: 94.240% (9424/10000)\n",
      "Epoch: 133\n",
      "Loss: 0.203 | Acc: 94.440% (9444/10000)\n",
      "Saving..\n",
      "Epoch: 134\n",
      "Loss: 0.207 | Acc: 94.290% (9429/10000)\n",
      "Epoch: 135\n",
      "Loss: 0.206 | Acc: 94.200% (9420/10000)\n",
      "Epoch: 136\n",
      "Loss: 0.208 | Acc: 94.360% (9436/10000)\n",
      "Epoch: 137\n",
      "Loss: 0.206 | Acc: 94.410% (9441/10000)\n",
      "Epoch: 138\n",
      "Loss: 0.203 | Acc: 94.300% (9430/10000)\n",
      "Epoch: 139\n",
      "Loss: 0.201 | Acc: 94.500% (9450/10000)\n",
      "Saving..\n",
      "Epoch: 140\n",
      "Loss: 0.198 | Acc: 94.600% (9460/10000)\n",
      "Saving..\n",
      "Epoch: 141\n",
      "Loss: 0.205 | Acc: 94.280% (9428/10000)\n",
      "Epoch: 142\n",
      "Loss: 0.211 | Acc: 94.220% (9422/10000)\n",
      "Epoch: 143\n",
      "Loss: 0.201 | Acc: 94.390% (9439/10000)\n",
      "Epoch: 144\n",
      "Loss: 0.210 | Acc: 94.390% (9439/10000)\n",
      "Epoch: 145\n",
      "Loss: 0.206 | Acc: 94.470% (9447/10000)\n",
      "Epoch: 146\n",
      "Loss: 0.209 | Acc: 94.460% (9446/10000)\n",
      "Epoch: 147\n",
      "Loss: 0.204 | Acc: 94.390% (9439/10000)\n",
      "Epoch: 148\n",
      "Loss: 0.201 | Acc: 94.590% (9459/10000)\n",
      "Epoch: 149\n",
      "Loss: 0.203 | Acc: 94.500% (9450/10000)\n",
      "Epoch: 150\n",
      "Loss: 0.208 | Acc: 94.460% (9446/10000)\n",
      "Epoch: 151\n",
      "Loss: 0.205 | Acc: 94.470% (9447/10000)\n",
      "Epoch: 152\n",
      "Loss: 0.207 | Acc: 94.280% (9428/10000)\n",
      "Epoch: 153\n",
      "Loss: 0.211 | Acc: 94.510% (9451/10000)\n",
      "Epoch: 154\n",
      "Loss: 0.204 | Acc: 94.380% (9438/10000)\n",
      "Epoch: 155\n",
      "Loss: 0.204 | Acc: 94.300% (9430/10000)\n",
      "Epoch: 156\n",
      "Loss: 0.207 | Acc: 94.310% (9431/10000)\n",
      "Epoch: 157\n",
      "Loss: 0.202 | Acc: 94.380% (9438/10000)\n",
      "Epoch: 158\n",
      "Loss: 0.202 | Acc: 94.500% (9450/10000)\n",
      "Epoch: 159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.201 | Acc: 94.590% (9459/10000)\n",
      "Epoch: 160\n",
      "Loss: 0.213 | Acc: 94.360% (9436/10000)\n",
      "Epoch: 161\n",
      "Loss: 0.194 | Acc: 94.710% (9471/10000)\n",
      "Saving..\n",
      "Epoch: 162\n",
      "Loss: 0.194 | Acc: 94.640% (9464/10000)\n",
      "Epoch: 163\n",
      "Loss: 0.194 | Acc: 94.740% (9474/10000)\n",
      "Saving..\n",
      "Epoch: 164\n",
      "Loss: 0.193 | Acc: 94.670% (9467/10000)\n",
      "Epoch: 165\n",
      "Loss: 0.193 | Acc: 94.730% (9473/10000)\n",
      "Epoch: 166\n",
      "Loss: 0.196 | Acc: 94.620% (9462/10000)\n",
      "Epoch: 167\n",
      "Loss: 0.194 | Acc: 94.780% (9478/10000)\n",
      "Saving..\n",
      "Epoch: 168\n",
      "Loss: 0.192 | Acc: 94.810% (9481/10000)\n",
      "Saving..\n",
      "Epoch: 169\n",
      "Loss: 0.194 | Acc: 94.710% (9471/10000)\n",
      "Epoch: 170\n",
      "Loss: 0.192 | Acc: 94.780% (9478/10000)\n",
      "Epoch: 171\n",
      "Loss: 0.193 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 172\n",
      "Loss: 0.193 | Acc: 94.730% (9473/10000)\n",
      "Epoch: 173\n",
      "Loss: 0.193 | Acc: 94.690% (9469/10000)\n",
      "Epoch: 174\n",
      "Loss: 0.193 | Acc: 94.670% (9467/10000)\n",
      "Epoch: 175\n",
      "Loss: 0.193 | Acc: 94.720% (9472/10000)\n",
      "Epoch: 176\n",
      "Loss: 0.192 | Acc: 94.590% (9459/10000)\n",
      "Epoch: 177\n",
      "Loss: 0.194 | Acc: 94.740% (9474/10000)\n",
      "Epoch: 178\n",
      "Loss: 0.194 | Acc: 94.670% (9467/10000)\n",
      "Epoch: 179\n",
      "Loss: 0.194 | Acc: 94.720% (9472/10000)\n",
      "Epoch: 180\n",
      "Loss: 0.192 | Acc: 94.780% (9478/10000)\n",
      "Epoch: 181\n",
      "Loss: 0.194 | Acc: 94.700% (9470/10000)\n",
      "Epoch: 182\n",
      "Loss: 0.193 | Acc: 94.700% (9470/10000)\n",
      "Epoch: 183\n",
      "Loss: 0.191 | Acc: 94.810% (9481/10000)\n",
      "Epoch: 184\n",
      "Loss: 0.192 | Acc: 94.750% (9475/10000)\n",
      "Epoch: 185\n",
      "Loss: 0.192 | Acc: 94.850% (9485/10000)\n",
      "Saving..\n",
      "Epoch: 186\n",
      "Loss: 0.194 | Acc: 94.860% (9486/10000)\n",
      "Saving..\n",
      "Epoch: 187\n",
      "Loss: 0.190 | Acc: 94.900% (9490/10000)\n",
      "Saving..\n",
      "Epoch: 188\n",
      "Loss: 0.190 | Acc: 94.750% (9475/10000)\n",
      "Epoch: 189\n",
      "Loss: 0.191 | Acc: 94.810% (9481/10000)\n",
      "Epoch: 190\n",
      "Loss: 0.193 | Acc: 94.730% (9473/10000)\n",
      "Epoch: 191\n",
      "Loss: 0.193 | Acc: 94.750% (9475/10000)\n",
      "Epoch: 192\n",
      "Loss: 0.193 | Acc: 94.820% (9482/10000)\n",
      "Epoch: 193\n",
      "Loss: 0.192 | Acc: 94.810% (9481/10000)\n",
      "Epoch: 194\n",
      "Loss: 0.193 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 195\n",
      "Loss: 0.194 | Acc: 94.760% (9476/10000)\n",
      "Epoch: 196\n",
      "Loss: 0.194 | Acc: 94.750% (9475/10000)\n",
      "Epoch: 197\n",
      "Loss: 0.192 | Acc: 94.820% (9482/10000)\n",
      "Epoch: 198\n",
      "Loss: 0.192 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 199\n",
      "Loss: 0.193 | Acc: 94.880% (9488/10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print('================> Building model {}..'.format(0))\n",
    "net =wrn(\n",
    "      num_classes=10,\n",
    "      depth=16,\n",
    "      widen_factor=5,\n",
    "      dropRate=0.3,\n",
    "    )\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "#Initialize Optimizer\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "#training and testing\n",
    "for epoch in range(start_epoch, start_epoch + 200):\n",
    "    train(epoch,train_loader,net)\n",
    "    test(epoch,val_loader,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd63fcb",
   "metadata": {},
   "source": [
    "### Testing of the final result, the best model is stored in ./checkpoint-no-cross: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6745291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.060\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./checkpoint-no-cross/\"\n",
    "\n",
    "net =wrn(\n",
    "      num_classes=10,\n",
    "      depth=16,\n",
    "      widen_factor=5,\n",
    "      dropRate=0.3,\n",
    "    )\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    checkpoint = torch.load(model_dir+'ckpt{}.pth'.format(0))\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "net.eval()\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100.*correct/total\n",
    "    print(\"Accuracy: %.3f\"%(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
