{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac710ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from utils import progress_bar\n",
    "from model_wrn import wrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4af1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing \n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6535b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "# parser.add_argument('--total_epoch', default=200,type=int)\n",
    "# parser.add_argument('--model_dir',default='./checkpoint_wrn/')\n",
    "# args = parser.parse_args()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710b20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load training images of CIFAR-10 twice: one for training, one for validation, with different preprocessing function\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2863d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to resume training process, ignored\n",
    "# if args.resume:\n",
    "#     # Load checkpoint.\n",
    "#     print('==> Resuming from checkpoint..')\n",
    "#     assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "#     checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "#     net.load_state_dict(checkpoint['net'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a469be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Learning Rate Schedule###\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if(epoch<61):\n",
    "        lr=0.1\n",
    "    elif(epoch<121):\n",
    "        lr=0.02\n",
    "    elif(epoch<161):\n",
    "        lr=0.004\n",
    "    elif(epoch<=200):\n",
    "        lr=0.0008\n",
    "    #print(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f94cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training Code###\n",
    "def train(epoch,dataLoader,model):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    print('Epoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataLoader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # progress_bar(batch_idx, len(dataLoader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f2f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Testing Code for model selection###\n",
    "def test(epoch,dataLoader,model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_num=0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataLoader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            batch_num+=1\n",
    "\n",
    "            # progress_bar(batch_idx, len(dataLoader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #     % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "    # Save best model according to the performance on validation set\n",
    "    acc = 100.*correct/total\n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_num), 100.*correct/total, correct, total))\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint-no-cross/' + 'ckpt{}.pth'.format(0))\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d17e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation: Parameter settings, shuffle the data order\n",
    "# model_num = 5\n",
    "# indices = list(range(len(train_dataset)))\n",
    "# random.shuffle(indices)\n",
    "# val_size = int(float(1/model_num)*len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d775944c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 80, 32, 32]          11,520\n",
      "       BatchNorm2d-5           [-1, 80, 32, 32]             160\n",
      "              ReLU-6           [-1, 80, 32, 32]               0\n",
      "            Conv2d-7           [-1, 80, 32, 32]          57,600\n",
      "            Conv2d-8           [-1, 80, 32, 32]           1,280\n",
      "        BasicBlock-9           [-1, 80, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 80, 32, 32]             160\n",
      "             ReLU-11           [-1, 80, 32, 32]               0\n",
      "           Conv2d-12           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-13           [-1, 80, 32, 32]             160\n",
      "             ReLU-14           [-1, 80, 32, 32]               0\n",
      "           Conv2d-15           [-1, 80, 32, 32]          57,600\n",
      "       BasicBlock-16           [-1, 80, 32, 32]               0\n",
      "     NetworkBlock-17           [-1, 80, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 80, 32, 32]             160\n",
      "             ReLU-19           [-1, 80, 32, 32]               0\n",
      "           Conv2d-20          [-1, 160, 16, 16]         115,200\n",
      "      BatchNorm2d-21          [-1, 160, 16, 16]             320\n",
      "             ReLU-22          [-1, 160, 16, 16]               0\n",
      "           Conv2d-23          [-1, 160, 16, 16]         230,400\n",
      "           Conv2d-24          [-1, 160, 16, 16]          12,800\n",
      "       BasicBlock-25          [-1, 160, 16, 16]               0\n",
      "      BatchNorm2d-26          [-1, 160, 16, 16]             320\n",
      "             ReLU-27          [-1, 160, 16, 16]               0\n",
      "           Conv2d-28          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-29          [-1, 160, 16, 16]             320\n",
      "             ReLU-30          [-1, 160, 16, 16]               0\n",
      "           Conv2d-31          [-1, 160, 16, 16]         230,400\n",
      "       BasicBlock-32          [-1, 160, 16, 16]               0\n",
      "     NetworkBlock-33          [-1, 160, 16, 16]               0\n",
      "      BatchNorm2d-34          [-1, 160, 16, 16]             320\n",
      "             ReLU-35          [-1, 160, 16, 16]               0\n",
      "           Conv2d-36            [-1, 320, 8, 8]         460,800\n",
      "      BatchNorm2d-37            [-1, 320, 8, 8]             640\n",
      "             ReLU-38            [-1, 320, 8, 8]               0\n",
      "           Conv2d-39            [-1, 320, 8, 8]         921,600\n",
      "           Conv2d-40            [-1, 320, 8, 8]          51,200\n",
      "       BasicBlock-41            [-1, 320, 8, 8]               0\n",
      "      BatchNorm2d-42            [-1, 320, 8, 8]             640\n",
      "             ReLU-43            [-1, 320, 8, 8]               0\n",
      "           Conv2d-44            [-1, 320, 8, 8]         921,600\n",
      "      BatchNorm2d-45            [-1, 320, 8, 8]             640\n",
      "             ReLU-46            [-1, 320, 8, 8]               0\n",
      "           Conv2d-47            [-1, 320, 8, 8]         921,600\n",
      "       BasicBlock-48            [-1, 320, 8, 8]               0\n",
      "     NetworkBlock-49            [-1, 320, 8, 8]               0\n",
      "      BatchNorm2d-50            [-1, 320, 8, 8]             640\n",
      "             ReLU-51            [-1, 320, 8, 8]               0\n",
      "           Linear-52                   [-1, 10]           3,210\n",
      "================================================================\n",
      "Total params: 4,289,754\n",
      "Trainable params: 4,289,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 17.88\n",
      "Params size (MB): 16.36\n",
      "Estimated Total Size (MB): 34.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "net = wrn(\n",
    "          num_classes=10,\n",
    "          depth=16,\n",
    "          widen_factor=5,\n",
    "          dropRate=0.3,\n",
    "        )\n",
    "net.cuda()\n",
    "torchsummary.summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308110f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> Building model 0..\n",
      "Epoch: 0\n",
      "Loss: 1.507 | Acc: 49.230% (4923/10000)\n",
      "Saving..\n",
      "Epoch: 1\n",
      "Loss: 0.929 | Acc: 67.560% (6756/10000)\n",
      "Saving..\n",
      "Epoch: 2\n",
      "Loss: 0.907 | Acc: 69.590% (6959/10000)\n",
      "Saving..\n",
      "Epoch: 3\n",
      "Loss: 0.824 | Acc: 72.860% (7286/10000)\n",
      "Saving..\n",
      "Epoch: 4\n",
      "Loss: 0.714 | Acc: 76.170% (7617/10000)\n",
      "Saving..\n",
      "Epoch: 5\n",
      "Loss: 0.749 | Acc: 75.620% (7562/10000)\n",
      "Epoch: 6\n",
      "Loss: 0.700 | Acc: 77.210% (7721/10000)\n",
      "Saving..\n",
      "Epoch: 7\n",
      "Loss: 0.696 | Acc: 78.000% (7800/10000)\n",
      "Saving..\n",
      "Epoch: 8\n",
      "Loss: 0.675 | Acc: 78.130% (7813/10000)\n",
      "Saving..\n",
      "Epoch: 9\n",
      "Loss: 0.837 | Acc: 75.110% (7511/10000)\n",
      "Epoch: 10\n",
      "Loss: 0.755 | Acc: 76.720% (7672/10000)\n",
      "Epoch: 11\n",
      "Loss: 0.595 | Acc: 80.680% (8068/10000)\n",
      "Saving..\n",
      "Epoch: 12\n",
      "Loss: 0.577 | Acc: 81.390% (8139/10000)\n",
      "Saving..\n",
      "Epoch: 13\n",
      "Loss: 0.502 | Acc: 83.340% (8334/10000)\n",
      "Saving..\n",
      "Epoch: 14\n",
      "Loss: 0.593 | Acc: 80.840% (8084/10000)\n",
      "Epoch: 15\n",
      "Loss: 0.569 | Acc: 81.670% (8167/10000)\n",
      "Epoch: 16\n",
      "Loss: 0.592 | Acc: 80.700% (8070/10000)\n",
      "Epoch: 17\n",
      "Loss: 0.577 | Acc: 81.360% (8136/10000)\n",
      "Epoch: 18\n",
      "Loss: 0.785 | Acc: 74.680% (7468/10000)\n",
      "Epoch: 19\n",
      "Loss: 0.561 | Acc: 81.690% (8169/10000)\n",
      "Epoch: 20\n",
      "Loss: 0.632 | Acc: 80.010% (8001/10000)\n",
      "Epoch: 21\n",
      "Loss: 0.702 | Acc: 78.460% (7846/10000)\n",
      "Epoch: 22\n",
      "Loss: 0.471 | Acc: 84.320% (8432/10000)\n",
      "Saving..\n",
      "Epoch: 23\n",
      "Loss: 0.572 | Acc: 81.870% (8187/10000)\n",
      "Epoch: 24\n",
      "Loss: 0.504 | Acc: 83.160% (8316/10000)\n",
      "Epoch: 25\n",
      "Loss: 0.738 | Acc: 77.710% (7771/10000)\n",
      "Epoch: 26\n",
      "Loss: 0.488 | Acc: 83.760% (8376/10000)\n",
      "Epoch: 27\n",
      "Loss: 0.511 | Acc: 83.080% (8308/10000)\n",
      "Epoch: 28\n",
      "Loss: 0.512 | Acc: 83.290% (8329/10000)\n",
      "Epoch: 29\n",
      "Loss: 0.452 | Acc: 84.890% (8489/10000)\n",
      "Saving..\n",
      "Epoch: 30\n",
      "Loss: 0.651 | Acc: 79.490% (7949/10000)\n",
      "Epoch: 31\n",
      "Loss: 0.610 | Acc: 80.210% (8021/10000)\n",
      "Epoch: 32\n",
      "Loss: 0.596 | Acc: 79.870% (7987/10000)\n",
      "Epoch: 33\n",
      "Loss: 0.441 | Acc: 85.570% (8557/10000)\n",
      "Saving..\n",
      "Epoch: 34\n",
      "Loss: 0.483 | Acc: 84.240% (8424/10000)\n",
      "Epoch: 35\n",
      "Loss: 0.483 | Acc: 84.140% (8414/10000)\n",
      "Epoch: 36\n",
      "Loss: 0.705 | Acc: 79.290% (7929/10000)\n",
      "Epoch: 37\n",
      "Loss: 0.581 | Acc: 81.250% (8125/10000)\n",
      "Epoch: 38\n",
      "Loss: 0.469 | Acc: 84.020% (8402/10000)\n",
      "Epoch: 39\n",
      "Loss: 0.527 | Acc: 82.390% (8239/10000)\n",
      "Epoch: 40\n",
      "Loss: 0.480 | Acc: 83.930% (8393/10000)\n",
      "Epoch: 41\n",
      "Loss: 0.578 | Acc: 82.020% (8202/10000)\n",
      "Epoch: 42\n",
      "Loss: 0.470 | Acc: 84.810% (8481/10000)\n",
      "Epoch: 43\n",
      "Loss: 0.420 | Acc: 85.980% (8598/10000)\n",
      "Saving..\n",
      "Epoch: 44\n",
      "Loss: 0.521 | Acc: 83.820% (8382/10000)\n",
      "Epoch: 45\n",
      "Loss: 0.488 | Acc: 83.490% (8349/10000)\n",
      "Epoch: 46\n",
      "Loss: 0.549 | Acc: 83.190% (8319/10000)\n",
      "Epoch: 47\n",
      "Loss: 0.537 | Acc: 82.970% (8297/10000)\n",
      "Epoch: 48\n",
      "Loss: 0.541 | Acc: 81.770% (8177/10000)\n",
      "Epoch: 49\n",
      "Loss: 0.468 | Acc: 85.090% (8509/10000)\n",
      "Epoch: 50\n",
      "Loss: 0.550 | Acc: 83.060% (8306/10000)\n",
      "Epoch: 51\n",
      "Loss: 0.540 | Acc: 82.830% (8283/10000)\n",
      "Epoch: 52\n",
      "Loss: 0.484 | Acc: 83.970% (8397/10000)\n",
      "Epoch: 53\n",
      "Loss: 0.486 | Acc: 84.070% (8407/10000)\n",
      "Epoch: 54\n",
      "Loss: 0.563 | Acc: 82.230% (8223/10000)\n",
      "Epoch: 55\n",
      "Loss: 0.454 | Acc: 84.740% (8474/10000)\n",
      "Epoch: 56\n",
      "Loss: 0.411 | Acc: 86.450% (8645/10000)\n",
      "Saving..\n",
      "Epoch: 57\n",
      "Loss: 0.514 | Acc: 83.200% (8320/10000)\n",
      "Epoch: 58\n",
      "Loss: 0.501 | Acc: 83.950% (8395/10000)\n",
      "Epoch: 59\n",
      "Loss: 0.496 | Acc: 84.240% (8424/10000)\n",
      "Epoch: 60\n",
      "Loss: 0.588 | Acc: 81.230% (8123/10000)\n",
      "Epoch: 61\n",
      "Loss: 0.224 | Acc: 92.370% (9237/10000)\n",
      "Saving..\n",
      "Epoch: 62\n",
      "Loss: 0.228 | Acc: 92.470% (9247/10000)\n",
      "Saving..\n",
      "Epoch: 63\n",
      "Loss: 0.230 | Acc: 92.640% (9264/10000)\n",
      "Saving..\n",
      "Epoch: 64\n",
      "Loss: 0.224 | Acc: 92.500% (9250/10000)\n",
      "Epoch: 65\n",
      "Loss: 0.229 | Acc: 92.640% (9264/10000)\n",
      "Epoch: 66\n",
      "Loss: 0.222 | Acc: 92.850% (9285/10000)\n",
      "Saving..\n",
      "Epoch: 67\n",
      "Loss: 0.230 | Acc: 92.640% (9264/10000)\n",
      "Epoch: 68\n",
      "Loss: 0.238 | Acc: 92.670% (9267/10000)\n",
      "Epoch: 69\n",
      "Loss: 0.249 | Acc: 92.060% (9206/10000)\n",
      "Epoch: 70\n",
      "Loss: 0.248 | Acc: 92.290% (9229/10000)\n",
      "Epoch: 71\n",
      "Loss: 0.262 | Acc: 92.030% (9203/10000)\n",
      "Epoch: 72\n",
      "Loss: 0.237 | Acc: 92.610% (9261/10000)\n",
      "Epoch: 73\n",
      "Loss: 0.258 | Acc: 92.090% (9209/10000)\n",
      "Epoch: 74\n",
      "Loss: 0.254 | Acc: 91.890% (9189/10000)\n",
      "Epoch: 75\n",
      "Loss: 0.254 | Acc: 91.990% (9199/10000)\n",
      "Epoch: 76\n",
      "Loss: 0.282 | Acc: 91.200% (9120/10000)\n",
      "Epoch: 77\n",
      "Loss: 0.285 | Acc: 91.210% (9121/10000)\n",
      "Epoch: 78\n",
      "Loss: 0.267 | Acc: 91.740% (9174/10000)\n",
      "Epoch: 79\n",
      "Loss: 0.258 | Acc: 91.990% (9199/10000)\n",
      "Epoch: 80\n",
      "Loss: 0.264 | Acc: 91.740% (9174/10000)\n",
      "Epoch: 81\n",
      "Loss: 0.278 | Acc: 92.000% (9200/10000)\n",
      "Epoch: 82\n",
      "Loss: 0.261 | Acc: 91.760% (9176/10000)\n",
      "Epoch: 83\n",
      "Loss: 0.275 | Acc: 91.520% (9152/10000)\n",
      "Epoch: 84\n",
      "Loss: 0.291 | Acc: 91.250% (9125/10000)\n",
      "Epoch: 85\n",
      "Loss: 0.260 | Acc: 91.820% (9182/10000)\n",
      "Epoch: 86\n",
      "Loss: 0.281 | Acc: 91.250% (9125/10000)\n",
      "Epoch: 87\n",
      "Loss: 0.297 | Acc: 90.870% (9087/10000)\n",
      "Epoch: 88\n",
      "Loss: 0.294 | Acc: 90.990% (9099/10000)\n",
      "Epoch: 89\n",
      "Loss: 0.270 | Acc: 92.020% (9202/10000)\n",
      "Epoch: 90\n",
      "Loss: 0.269 | Acc: 91.800% (9180/10000)\n",
      "Epoch: 91\n",
      "Loss: 0.269 | Acc: 91.710% (9171/10000)\n",
      "Epoch: 92\n",
      "Loss: 0.276 | Acc: 91.690% (9169/10000)\n",
      "Epoch: 93\n",
      "Loss: 0.291 | Acc: 91.180% (9118/10000)\n",
      "Epoch: 94\n",
      "Loss: 0.296 | Acc: 91.040% (9104/10000)\n",
      "Epoch: 95\n",
      "Loss: 0.290 | Acc: 91.310% (9131/10000)\n",
      "Epoch: 96\n",
      "Loss: 0.292 | Acc: 91.310% (9131/10000)\n",
      "Epoch: 97\n",
      "Loss: 0.299 | Acc: 91.180% (9118/10000)\n",
      "Epoch: 98\n",
      "Loss: 0.301 | Acc: 91.160% (9116/10000)\n",
      "Epoch: 99\n",
      "Loss: 0.262 | Acc: 91.860% (9186/10000)\n",
      "Epoch: 100\n",
      "Loss: 0.282 | Acc: 91.240% (9124/10000)\n",
      "Epoch: 101\n",
      "Loss: 0.295 | Acc: 91.040% (9104/10000)\n",
      "Epoch: 102\n",
      "Loss: 0.277 | Acc: 91.590% (9159/10000)\n",
      "Epoch: 103\n",
      "Loss: 0.293 | Acc: 91.350% (9135/10000)\n",
      "Epoch: 104\n",
      "Loss: 0.295 | Acc: 91.410% (9141/10000)\n",
      "Epoch: 105\n",
      "Loss: 0.297 | Acc: 91.250% (9125/10000)\n",
      "Epoch: 106\n",
      "Loss: 0.272 | Acc: 91.750% (9175/10000)\n",
      "Epoch: 107\n",
      "Loss: 0.289 | Acc: 91.100% (9110/10000)\n",
      "Epoch: 108\n",
      "Loss: 0.283 | Acc: 91.390% (9139/10000)\n",
      "Epoch: 109\n",
      "Loss: 0.283 | Acc: 91.830% (9183/10000)\n",
      "Epoch: 110\n",
      "Loss: 0.298 | Acc: 90.940% (9094/10000)\n",
      "Epoch: 111\n",
      "Loss: 0.292 | Acc: 91.230% (9123/10000)\n",
      "Epoch: 112\n",
      "Loss: 0.264 | Acc: 91.850% (9185/10000)\n",
      "Epoch: 113\n",
      "Loss: 0.270 | Acc: 91.760% (9176/10000)\n",
      "Epoch: 114\n",
      "Loss: 0.299 | Acc: 91.290% (9129/10000)\n",
      "Epoch: 115\n",
      "Loss: 0.308 | Acc: 90.930% (9093/10000)\n",
      "Epoch: 116\n",
      "Loss: 0.321 | Acc: 90.510% (9051/10000)\n",
      "Epoch: 117\n",
      "Loss: 0.293 | Acc: 91.150% (9115/10000)\n",
      "Epoch: 118\n",
      "Loss: 0.256 | Acc: 91.940% (9194/10000)\n",
      "Epoch: 119\n",
      "Loss: 0.299 | Acc: 91.340% (9134/10000)\n",
      "Epoch: 120\n",
      "Loss: 0.295 | Acc: 91.300% (9130/10000)\n",
      "Epoch: 121\n",
      "Loss: 0.199 | Acc: 94.110% (9411/10000)\n",
      "Saving..\n",
      "Epoch: 122\n",
      "Loss: 0.197 | Acc: 94.270% (9427/10000)\n",
      "Saving..\n",
      "Epoch: 123\n",
      "Loss: 0.195 | Acc: 94.180% (9418/10000)\n",
      "Epoch: 124\n",
      "Loss: 0.201 | Acc: 94.320% (9432/10000)\n",
      "Saving..\n",
      "Epoch: 125\n",
      "Loss: 0.199 | Acc: 94.300% (9430/10000)\n",
      "Epoch: 126\n",
      "Loss: 0.196 | Acc: 94.520% (9452/10000)\n",
      "Saving..\n",
      "Epoch: 127\n",
      "Loss: 0.196 | Acc: 94.590% (9459/10000)\n",
      "Saving..\n",
      "Epoch: 128\n",
      "Loss: 0.194 | Acc: 94.580% (9458/10000)\n",
      "Epoch: 129\n",
      "Loss: 0.204 | Acc: 94.420% (9442/10000)\n",
      "Epoch: 130\n",
      "Loss: 0.198 | Acc: 94.530% (9453/10000)\n",
      "Epoch: 131\n",
      "Loss: 0.201 | Acc: 94.560% (9456/10000)\n",
      "Epoch: 132\n",
      "Loss: 0.206 | Acc: 94.370% (9437/10000)\n",
      "Epoch: 133\n",
      "Loss: 0.198 | Acc: 94.650% (9465/10000)\n",
      "Saving..\n",
      "Epoch: 134\n",
      "Loss: 0.195 | Acc: 94.830% (9483/10000)\n",
      "Saving..\n",
      "Epoch: 135\n",
      "Loss: 0.195 | Acc: 94.810% (9481/10000)\n",
      "Epoch: 136\n",
      "Loss: 0.207 | Acc: 94.410% (9441/10000)\n",
      "Epoch: 137\n",
      "Loss: 0.194 | Acc: 94.760% (9476/10000)\n",
      "Epoch: 138\n",
      "Loss: 0.201 | Acc: 94.780% (9478/10000)\n",
      "Epoch: 139\n",
      "Loss: 0.201 | Acc: 94.640% (9464/10000)\n",
      "Epoch: 140\n",
      "Loss: 0.207 | Acc: 94.510% (9451/10000)\n",
      "Epoch: 141\n",
      "Loss: 0.202 | Acc: 94.720% (9472/10000)\n",
      "Epoch: 142\n",
      "Loss: 0.202 | Acc: 94.480% (9448/10000)\n",
      "Epoch: 143\n",
      "Loss: 0.198 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 144\n",
      "Loss: 0.196 | Acc: 94.710% (9471/10000)\n",
      "Epoch: 145\n",
      "Loss: 0.201 | Acc: 94.700% (9470/10000)\n",
      "Epoch: 146\n",
      "Loss: 0.205 | Acc: 94.600% (9460/10000)\n",
      "Epoch: 147\n",
      "Loss: 0.200 | Acc: 94.620% (9462/10000)\n",
      "Epoch: 148\n",
      "Loss: 0.200 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 149\n",
      "Loss: 0.202 | Acc: 94.710% (9471/10000)\n",
      "Epoch: 150\n",
      "Loss: 0.196 | Acc: 94.840% (9484/10000)\n",
      "Saving..\n",
      "Epoch: 151\n",
      "Loss: 0.211 | Acc: 94.540% (9454/10000)\n",
      "Epoch: 152\n",
      "Loss: 0.206 | Acc: 94.720% (9472/10000)\n",
      "Epoch: 153\n",
      "Loss: 0.202 | Acc: 94.690% (9469/10000)\n",
      "Epoch: 154\n",
      "Loss: 0.199 | Acc: 94.840% (9484/10000)\n",
      "Epoch: 155\n",
      "Loss: 0.204 | Acc: 94.520% (9452/10000)\n",
      "Epoch: 156\n",
      "Loss: 0.212 | Acc: 94.500% (9450/10000)\n",
      "Epoch: 157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.198 | Acc: 94.770% (9477/10000)\n",
      "Epoch: 158\n",
      "Loss: 0.201 | Acc: 94.690% (9469/10000)\n",
      "Epoch: 159\n",
      "Loss: 0.204 | Acc: 94.760% (9476/10000)\n",
      "Epoch: 160\n",
      "Loss: 0.204 | Acc: 94.630% (9463/10000)\n",
      "Epoch: 161\n",
      "Loss: 0.198 | Acc: 94.840% (9484/10000)\n",
      "Epoch: 162\n",
      "Loss: 0.193 | Acc: 94.870% (9487/10000)\n",
      "Saving..\n",
      "Epoch: 163\n",
      "Loss: 0.193 | Acc: 94.910% (9491/10000)\n",
      "Saving..\n",
      "Epoch: 164\n",
      "Loss: 0.193 | Acc: 94.970% (9497/10000)\n",
      "Saving..\n",
      "Epoch: 165\n",
      "Loss: 0.192 | Acc: 94.990% (9499/10000)\n",
      "Saving..\n",
      "Epoch: 166\n",
      "Loss: 0.193 | Acc: 94.940% (9494/10000)\n",
      "Epoch: 167\n",
      "Loss: 0.193 | Acc: 94.870% (9487/10000)\n",
      "Epoch: 168\n",
      "Loss: 0.192 | Acc: 94.930% (9493/10000)\n",
      "Epoch: 169\n",
      "Loss: 0.192 | Acc: 94.960% (9496/10000)\n",
      "Epoch: 170\n",
      "Loss: 0.193 | Acc: 94.970% (9497/10000)\n",
      "Epoch: 171\n",
      "Loss: 0.194 | Acc: 95.010% (9501/10000)\n",
      "Saving..\n",
      "Epoch: 172\n",
      "Loss: 0.193 | Acc: 94.990% (9499/10000)\n",
      "Epoch: 173\n",
      "Loss: 0.194 | Acc: 95.050% (9505/10000)\n",
      "Saving..\n",
      "Epoch: 174\n",
      "Loss: 0.194 | Acc: 95.010% (9501/10000)\n",
      "Epoch: 175\n",
      "Loss: 0.193 | Acc: 95.030% (9503/10000)\n",
      "Epoch: 176\n",
      "Loss: 0.194 | Acc: 95.060% (9506/10000)\n",
      "Saving..\n",
      "Epoch: 177\n",
      "Loss: 0.194 | Acc: 94.980% (9498/10000)\n",
      "Epoch: 178\n",
      "Loss: 0.194 | Acc: 95.010% (9501/10000)\n",
      "Epoch: 179\n",
      "Loss: 0.194 | Acc: 94.940% (9494/10000)\n",
      "Epoch: 180\n",
      "Loss: 0.195 | Acc: 94.960% (9496/10000)\n",
      "Epoch: 181\n",
      "Loss: 0.195 | Acc: 94.930% (9493/10000)\n",
      "Epoch: 182\n",
      "Loss: 0.192 | Acc: 94.970% (9497/10000)\n",
      "Epoch: 183\n",
      "Loss: 0.193 | Acc: 95.020% (9502/10000)\n",
      "Epoch: 184\n",
      "Loss: 0.195 | Acc: 94.930% (9493/10000)\n",
      "Epoch: 185\n",
      "Loss: 0.193 | Acc: 94.940% (9494/10000)\n",
      "Epoch: 186\n",
      "Loss: 0.194 | Acc: 95.000% (9500/10000)\n",
      "Epoch: 187\n",
      "Loss: 0.196 | Acc: 94.930% (9493/10000)\n",
      "Epoch: 188\n",
      "Loss: 0.194 | Acc: 94.970% (9497/10000)\n",
      "Epoch: 189\n",
      "Loss: 0.195 | Acc: 94.940% (9494/10000)\n",
      "Epoch: 190\n",
      "Loss: 0.197 | Acc: 94.860% (9486/10000)\n",
      "Epoch: 191\n",
      "Loss: 0.194 | Acc: 95.050% (9505/10000)\n",
      "Epoch: 192\n",
      "Loss: 0.195 | Acc: 94.970% (9497/10000)\n",
      "Epoch: 193\n",
      "Loss: 0.193 | Acc: 95.010% (9501/10000)\n",
      "Epoch: 194\n",
      "Loss: 0.193 | Acc: 94.860% (9486/10000)\n",
      "Epoch: 195\n",
      "Loss: 0.194 | Acc: 95.060% (9506/10000)\n",
      "Epoch: 196\n",
      "Loss: 0.193 | Acc: 95.030% (9503/10000)\n",
      "Epoch: 197\n",
      "Loss: 0.194 | Acc: 94.980% (9498/10000)\n",
      "Epoch: 198\n",
      "Loss: 0.194 | Acc: 94.940% (9494/10000)\n",
      "Epoch: 199\n",
      "Loss: 0.196 | Acc: 94.920% (9492/10000)\n"
     ]
    }
   ],
   "source": [
    "# for model_index in range(model_num):\n",
    "    #Split Dataset\n",
    "#     val_indices = indices[val_size * model_index: val_size*(model_index+1)]\n",
    "#     train_indices = indices[:val_size*model_index]+indices[val_size* \\\n",
    "#             (model_index+1):]         \n",
    "#     train_sampler = SubsetRandomSampler(train_indices)\n",
    "#     val_sampler = SubsetRandomSampler(val_indices)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#Initialize Baseline Model\n",
    "print('================> Building model {}..'.format(0))\n",
    "net =wrn(\n",
    "      num_classes=10,\n",
    "      depth=16,\n",
    "      widen_factor=5,\n",
    "      dropRate=0.3,\n",
    "    )\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "#Initialize Optimizer\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "#training and testing\n",
    "for epoch in range(start_epoch, start_epoch + 200):\n",
    "    train(epoch,train_loader,net)\n",
    "    test(epoch,val_loader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6745291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.060\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./checkpoint-no-cross/\"\n",
    "#creating model\n",
    "# for model_index in range(model_num):\n",
    "#     print(\"Processing model %d\"%(model_index))\n",
    "net =wrn(\n",
    "      num_classes=10,\n",
    "      depth=16,\n",
    "      widen_factor=5,\n",
    "      dropRate=0.3,\n",
    "    )\n",
    "net = net.to(device)\n",
    "\n",
    "#load checkpoint to the model\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    checkpoint = torch.load(model_dir+'ckpt{}.pth'.format(0))\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "net.eval()\n",
    "    #store the results in a list\n",
    "#     results=[]\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "    #vprediction\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "#         outputs = net(inputs)#predict using the model\n",
    "#         outputs = outputs.squeeze(0)\n",
    "            \n",
    "#             results.append(outputs.cpu().numpy())#append the current result to the list\n",
    "\n",
    "#     results = np.array(results)#convert results from tensors to nparray\n",
    "\n",
    "#     for i in range(len(results)):\n",
    "#         for j in range(class_num):\n",
    "#             best_results[i][j] += results[i][j]# adding up the results in order to do soft vote\n",
    "    acc = 100.*correct/total\n",
    "    print(\"Accuracy: %.3f\"%(acc))\n",
    "# best_results = np.argmax(best_results,1)# using soft vote to find the best prediction\n",
    "\n",
    "# print(\"finished all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e9188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
